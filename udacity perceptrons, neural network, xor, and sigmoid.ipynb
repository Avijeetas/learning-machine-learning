{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# \n",
    "# In this exercise, you will put the finishing touches on a perceptron class.\n",
    "#\n",
    "# Finish writing the activate() method by using np.dot to compute signal\n",
    "# strength and then add in a threshold for perceptron activation.\n",
    "#\n",
    "# ----------\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    This class models an artificial neuron with step activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights = np.array([1]), threshold = 0):\n",
    "        \"\"\"\n",
    "        Initialize weights and threshold based on input arguments. Note that no\n",
    "        type-checking is being performed here for simplicity.\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def activate(self,inputs):\n",
    "        \"\"\"\n",
    "        Takes in @param inputs, a list of numbers equal to length of weights.\n",
    "        @return the output of a threshold perceptron with given inputs based on\n",
    "        perceptron weights and threshold.\n",
    "        \"\"\" \n",
    "\n",
    "        # INSERT YOUR CODE HERE\n",
    "\n",
    "        # TODO: calculate the strength with which the perceptron fires\n",
    "        result = np.dot(inputs, self.weights)\n",
    "        \n",
    "        # TODO: return 0 or 1 based on the threshold\n",
    "        return result > self.threshold\n",
    "\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    Nothing should show up in the output if all the assertions pass.\n",
    "    \"\"\"\n",
    "    p1 = Perceptron(np.array([1, 2]), 0.)\n",
    "    assert p1.activate(np.array([ 1,-1])) == 0 # < threshold --> 0\n",
    "    assert p1.activate(np.array([-1, 1])) == 1 # > threshold --> 1\n",
    "    assert p1.activate(np.array([ 2,-1])) == 0 # on threshold --> 0\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [delta rule](https://en.wikipedia.org/wiki/Delta_rule)\n",
    "\n",
    "### from slide:\n",
    "\\begin{align}w_i:=w_i + \\Delta w_i \\end{align}\n",
    "\\begin{align}\\Delta w_i=\\eta(y - \\hat{y}) x_i \\end{align}\n",
    "\\begin{align}\\hat{y}=(\\sum_{i} w_i x_i) \\ge 0\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 0 = expected 1 for input [ 2  0 -3] and weights [ 1.  1.  1.]\n",
      "new weights [ 1.2  1.   0.7] new prediction 1\n",
      "prediction 1 = expected 0 for input [3 2 1] and weights [ 1.  2.  3.]\n",
      "new weights [ 0.7  1.8  2.9] new prediction 1\n",
      "prediction 0 = expected 0 for input [ 4  0 -1] and weights [ 0.7  1.8  2.9]\n",
      "new weights [ 0.7  1.8  2.9] new prediction 0\n",
      "prediction 1 = expected 0 for input [ 2 -2  4] and weights [ 3.  0.  2.]\n",
      "new weights [ 2.8  0.2  1.6] new prediction 1\n",
      "prediction 0 = expected 1 for input [-1 -3  2] and weights [ 2.8  0.2  1.6]\n",
      "new weights [ 2.7 -0.1  1.8] new prediction 1\n",
      "prediction 1 = expected 0 for input [0 2 1] and weights [ 2.7 -0.1  1.8]\n",
      "new weights [ 2.7 -0.3  1.7] new prediction 1\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#\n",
    "# In this exercise, you will update the perceptron class so that it can update\n",
    "# its weights.\n",
    "#\n",
    "# Finish writing the update() method so that it updates the weights according\n",
    "# to the perceptron update rule. Updates should be performed online, revising\n",
    "# the weights after each data point.\n",
    "# \n",
    "# ----------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    This class models an artificial neuron with step activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights = np.array([1]), threshold = 0):\n",
    "        \"\"\"\n",
    "        Initialize weights and threshold based on input arguments. Note that no\n",
    "        type-checking is being performed here for simplicity.\n",
    "        \"\"\"\n",
    "        self.weights = weights.astype(float) \n",
    "        self.threshold = threshold\n",
    "\n",
    "\n",
    "    def activate(self, values):\n",
    "        \"\"\"\n",
    "        Takes in @param values, a list of numbers equal to length of weights.\n",
    "        @return the output of a threshold perceptron with given inputs based on\n",
    "        perceptron weights and threshold.\n",
    "        \"\"\"\n",
    "               \n",
    "        # First calculate the strength with which the perceptron fires\n",
    "        strength = self.strength(values)\n",
    "        \n",
    "        # Then return 0 or 1 depending on strength compared to threshold  \n",
    "        return int(strength > self.threshold)\n",
    "\n",
    "    def strength(self, values):\n",
    "        return np.dot(values,self.weights)\n",
    "\n",
    "    def update(self, values, train, eta=.1):\n",
    "        \"\"\"\n",
    "        Takes in a 2D array @param values consisting of a LIST of inputs and a\n",
    "        1D array @param train, consisting of a corresponding list of expected\n",
    "        outputs. Updates internal weights according to the perceptron training\n",
    "        rule using these values and an optional learning rate, @param eta.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # TODO: for each data point...\n",
    "        for index, x in enumerate(values):\n",
    "            # TODO: obtain the neuron's prediction for that point\n",
    "            y_hat = self.activate(x)\n",
    "            y = train[index]\n",
    "            print(\"prediction {} = expected {} for input {} and weights {}\".format(y_hat, y, x, self.weights))\n",
    "\n",
    "            for i, x_i in enumerate(x):\n",
    "                # TODO: update self.weights based on prediction accuracy, learning\n",
    "                # rate and input value\n",
    "                self.weights[i] += eta * (y - y_hat) * x_i\n",
    "            print(\"new weights {} new prediction {}\".format(self.weights, self.activate(x)))\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    Nothing should show up in the output if all the assertions pass.\n",
    "    \"\"\"\n",
    "    def sum_almost_equal(array1, array2, tol = 1e-6):\n",
    "        return sum(abs(array1 - array2)) < tol\n",
    "\n",
    "    p1 = Perceptron(np.array([1,1,1]),0)\n",
    "    p1.update(np.array([[2,0,-3]]), np.array([1]))\n",
    "    assert sum_almost_equal(p1.weights, np.array([1.2, 1, 0.7]))\n",
    "\n",
    "    p2 = Perceptron(np.array([1,2,3]),0)\n",
    "    p2.update(np.array([[3,2,1],[4,0,-1]]),np.array([0,0]))\n",
    "    assert sum_almost_equal(p2.weights, np.array([0.7, 1.8, 2.9]))\n",
    "\n",
    "    p3 = Perceptron(np.array([3,0,2]),0)\n",
    "    p3.update(np.array([[2,-2,4],[-1,-3,2],[0,2,1]]),np.array([0,1,0]))\n",
    "    assert sum_almost_equal(p3.weights, np.array([2.7, -0.3, 1.7]))\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-enterprise.discourse.org/udacity/uploads/default/original/3X/9/4/942a1b4ed344d005e2ba810380f049e8cfdf23fb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = np.array([1,2,3])\n",
    "hidden_perceptron_1 = Perceptron(np.array([1,1,-5]),0)\n",
    "hidden_perceptron_2 = Perceptron(np.array([3,-4,2]),0)\n",
    "output_perceptron = Perceptron(np.array([2,-1]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = 0\n"
     ]
    }
   ],
   "source": [
    "# fun with activation\n",
    "hidden_output_1 = hidden_perceptron_1.activate(input)\n",
    "hidden_output_2 = hidden_perceptron_2.activate(input)\n",
    "print(\"result = {}\".format(output_perceptron.activate(np.array([hidden_output_1, hidden_output_2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = -25.0\n"
     ]
    }
   ],
   "source": [
    "# fun with strength\n",
    "hidden_output_1 = hidden_perceptron_1.strength(input)\n",
    "hidden_output_2 = hidden_perceptron_2.strength(input)\n",
    "print(\"result = {}\".format(output_perceptron.strength(np.array([hidden_output_1, hidden_output_2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 XOR 0 = 0?: 0\n",
      "0 XOR 1 = 1?: 1\n",
      "1 XOR 0 = 1?: 1\n",
      "1 XOR 1 = 0?: 0\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#\n",
    "# In this exercise, you will create a network of perceptrons that can represent\n",
    "# the XOR function, using a network structure like those shown in the previous\n",
    "# quizzes.\n",
    "#\n",
    "# You will need to do two things:\n",
    "# First, create a network of perceptrons with the correct weights\n",
    "# Second, define a procedure EvalNetwork() which takes in a list of inputs and\n",
    "# outputs the value of this network.\n",
    "#\n",
    "# ----------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    This class models an artificial neuron with step activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights = np.array([1]), threshold = 0):\n",
    "        \"\"\"\n",
    "        Initialize weights and threshold based on input arguments. Note that no\n",
    "        type-checking is being performed here for simplicity.\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.threshold = threshold\n",
    "\n",
    "\n",
    "    def activate(self, values):\n",
    "        \"\"\"\n",
    "        Takes in @param values, a list of numbers equal to length of weights.\n",
    "        @return the output of a threshold perceptron with given inputs based on\n",
    "        perceptron weights and threshold.\n",
    "        \"\"\"\n",
    "               \n",
    "        # First calculate the strength with which the perceptron fires\n",
    "        strength = np.dot(values,self.weights)\n",
    "        \n",
    "        # Then return 0 or 1 depending on strength compared to threshold  \n",
    "        return int(strength > self.threshold)\n",
    "\n",
    "            \n",
    "# Part 1: Set up the perceptron network\n",
    "Network = [\n",
    "    # input layer, declare input layer perceptrons here\n",
    "    [ Perceptron(np.array([1,0])), Perceptron(np.array([1,1]), 1), Perceptron(np.array([0,1])) ], \\\n",
    "    # output node, declare output layer perceptron here\n",
    "    [ Perceptron(np.array([1,-2,1])) ]\n",
    "]\n",
    "\n",
    "# Part 2: Define a procedure to compute the output of the network, given inputs\n",
    "def EvalNetwork(inputValues, Network):\n",
    "    \"\"\"\n",
    "    Takes in @param inputValues, a list of input values, and @param Network\n",
    "    that specifies a perceptron network. @return the output of the Network for\n",
    "    the given set of inputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    OutputValue = Network[1][0].activate(np.array([\n",
    "                Network[0][0].activate(inputValues), \n",
    "                Network[0][1].activate(inputValues), \n",
    "                Network[0][2].activate(inputValues)]))\n",
    "\n",
    "    # Be sure your output value is a single number\n",
    "    return OutputValue\n",
    "\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    \"\"\"\n",
    "    print \"0 XOR 0 = 0?:\", EvalNetwork(np.array([0,0]), Network)\n",
    "    print \"0 XOR 1 = 1?:\", EvalNetwork(np.array([0,1]), Network)\n",
    "    print \"1 XOR 0 = 1?:\", EvalNetwork(np.array([1,0]), Network)\n",
    "    print \"1 XOR 1 = 0?:\", EvalNetwork(np.array([1,1]), Network)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [further reading](https://rolisz.ro/2013/04/18/neural-networks-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "# \n",
    "# As with the previous perceptron exercises, you will complete some of the core\n",
    "# methods of a sigmoid unit class.\n",
    "#\n",
    "# There are two functions for you to finish:\n",
    "# First, in activate(), write the sigmoid activation function.\n",
    "# Second, in update(), write the gradient descent update rule. Updates should be\n",
    "#   performed online, revising the weights after each data point.\n",
    "# \n",
    "# ----------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"\n",
    "    This class models an artificial neuron with sigmoid activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights = np.array([1])):\n",
    "        \"\"\"\n",
    "        Initialize weights based on input arguments. Note that no type-checking\n",
    "        is being performed here for simplicity of code.\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "\n",
    "        # NOTE: You do not need to worry about these two attribues for this\n",
    "        # programming quiz, but these will be useful for if you want to create\n",
    "        # a network out of these sigmoid units!\n",
    "        self.last_input = 0 # strength of last input\n",
    "        self.delta      = 0 # error signal\n",
    "\n",
    "    def activate(self, values):\n",
    "        \"\"\"\n",
    "        Takes in @param values, a list of numbers equal to length of weights.\n",
    "        @return the output of a sigmoid unit with given inputs based on unit\n",
    "        weights.\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # First calculate the strength of the input signal.\n",
    "        strength = np.dot(values, self.weights)\n",
    "        self.last_input = strength\n",
    "        \n",
    "        # TODO: Modify strength using the sigmoid activation function and\n",
    "        # return as output signal.\n",
    "        # HINT: You may want to create a helper function to compute the\n",
    "        #   logistic function since you will need it for the update function.\n",
    "        \n",
    "        return Sigmoid.logistic(strength)\n",
    "    \n",
    "    # https://rolisz.ro/2013/04/18/neural-networks-in-python/\n",
    "    @staticmethod\n",
    "    def logistic(x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    # https://rolisz.ro/2013/04/18/neural-networks-in-python/\n",
    "    @staticmethod\n",
    "    def logistic_derivative(x):\n",
    "        return Sigmoid.logistic(x)*(1-Sigmoid.logistic(x))\n",
    "\n",
    "    def update(self, values, train, eta=.1):\n",
    "        \"\"\"\n",
    "        Takes in a 2D array @param values consisting of a LIST of inputs and a\n",
    "        1D array @param train, consisting of a corresponding list of expected\n",
    "        outputs. Updates internal weights according to gradient descent using\n",
    "        these values and an optional learning rate, @param eta.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: for each data point...\n",
    "        for X, y_true in zip(values, train):\n",
    "            # obtain the output signal for that point\n",
    "            y_pred = self.activate(X)\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "\n",
    "            # TODO: compute derivative of logistic function at input strength\n",
    "            # Recall: d/dx logistic(x) = logistic(x)*(1-logistic(x))\n",
    "            deriv = Sigmoid.logistic_derivative(self.last_input)\n",
    "\n",
    "            # TODO: update self.weights based on learning rate, signal accuracy,\n",
    "            # function slope (derivative) and input value\n",
    "            # w_i += eta * (t - y) * g'(x) * x_i\n",
    "            for i, x_i in enumerate(X):\n",
    "                self.weights[i] += eta * (y_true - y_pred) * deriv * x_i\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    Nothing should show up in the output if all the assertions pass.\n",
    "    \"\"\"\n",
    "    def sum_almost_equal(array1, array2, tol = 1e-5):\n",
    "        return sum(abs(array1 - array2)) < tol\n",
    "\n",
    "    u1 = Sigmoid(weights=[3,-2,1])\n",
    "    assert abs(u1.activate(np.array([1,2,3])) - 0.880797) < 1e-5\n",
    "    \n",
    "    u1.update(np.array([[1,2,3]]),np.array([0]))\n",
    "    assert sum_almost_equal(u1.weights, np.array([2.990752, -2.018496, 0.972257]))\n",
    "\n",
    "    u2 = Sigmoid(weights=[0,3,-1])\n",
    "    u2.update(np.array([[-3,-1,2],[2,1,2]]),np.array([1,0]))\n",
    "    assert sum_almost_equal(u2.weights, np.array([-0.030739, 2.984961, -1.027437]))\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
